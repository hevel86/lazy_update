---
# Simple NVIDIA Driver Installation Playbook for Ubuntu/Debian
# Optimized for headless compute servers (Tdarr, Plex, Frigate)

- name: NVIDIA Driver Installation
  hosts: "{{ target_hosts | default('all') }}"
  become: true
  gather_facts: true
  
  vars:
    # Configuration variables
    nvidia_driver_version: latest  # Can be set to specific version like "525"
    restart_after_install: "{{ var_reboot | default('false') }}"  # Get reboot preference from Semaphore
    var_environment: "{{ var_environment | default('test') }}"    # Get environment from Semaphore
  
  tasks:
    - name: Check if NVIDIA GPU is present
      shell: lspci | grep -i nvidia
      register: nvidia_check
      changed_when: false
      failed_when: false
      
    - name: Set NVIDIA present fact
      set_fact:
        nvidia_present: "{{ nvidia_check.rc == 0 }}"
      
    - name: Display NVIDIA GPU detection result
      debug:
        msg: "NVIDIA GPU {{ 'detected' if nvidia_present else 'not detected' }}"
        
    - name: Display the current environment mode
      debug:
        msg: >
          {% if var_environment == "production" %}
            "Running in PRODUCTION mode: Will install the driver if newer."
          {% else %}
            "Running in TEST mode: Will only print driver versions."
          {% endif %}
        
    - name: Exit playbook if no NVIDIA GPU detected
      meta: end_play
      when: not nvidia_present
      
    # Check current driver status
    - name: Check if NVIDIA driver is already installed
      shell: "command -v nvidia-smi && nvidia-smi"
      register: nvidia_smi_result
      changed_when: false
      failed_when: false
      
    - name: Set driver installed fact
      set_fact:
        driver_installed: "{{ nvidia_smi_result.rc == 0 }}"
        
    - name: Get current driver version if installed
      shell: "nvidia-smi --query-gpu=driver_version --format=csv,noheader | head -n 1"
      register: current_driver_version
      when: driver_installed
      changed_when: false
      failed_when: false
      
    - name: Display current driver information
      debug:
        msg: "NVIDIA driver {{ current_driver_version.stdout | default('not installed') }}"
      when: driver_installed
        
    - name: Find available NVIDIA drivers
      shell: ubuntu-drivers devices | grep -i nvidia
      register: nvidia_drivers_output
      changed_when: false
      failed_when: false
      
    - name: Display all available NVIDIA drivers
      debug:
        var: nvidia_drivers_output.stdout_lines
      
    - name: Extract recommended NVIDIA driver
      shell: ubuntu-drivers devices | grep "recommended" | awk '{print $3}'
      register: recommended_driver
      changed_when: false
      failed_when: false
      
    - name: Display recommended driver information
      debug:
        msg: "Recommended NVIDIA driver: {{ recommended_driver.stdout | default('No recommended driver found') }}"
      
    - name: Set driver package - use recommended if found
      set_fact:
        nvidia_driver_package: "{{ recommended_driver.stdout }}"
      when: recommended_driver.stdout != ""
      
    - name: Set driver package - use server driver if no recommendation
      set_fact:
        nvidia_driver_package: "nvidia-driver-{{ nvidia_driver_version }}-server"
      when: recommended_driver.stdout == ""
      
    - name: Display driver to be installed
      debug:
        msg: "Driver package to install: {{ nvidia_driver_package }}"
      
    # Ubuntu/Debian driver installation
    - name: Install required dependencies
      apt:
        name:
          - software-properties-common
          - ubuntu-drivers-common
          - build-essential
          - dkms
        state: present
        
    - name: Add NVIDIA PPA repository
      apt_repository:
        repo: ppa:graphics-drivers/ppa
        state: present
        
    - name: Update apt cache
      apt:
        update_cache: yes
        
    # Install NVIDIA driver
    - name: Install NVIDIA driver
      apt:
        name: "{{ nvidia_driver_package }}"
        state: present
        update_cache: yes
      register: driver_install
      when: 
        - not driver_installed or (driver_installed and recommended_driver.stdout != current_driver_version.stdout)
        - var_environment == "production"
      
    # Display CUDA information if driver is installed
    - name: Check NVIDIA driver and CUDA version
      shell: "nvidia-smi"
      register: nvidia_smi_output
      changed_when: false
      failed_when: false
      when: driver_installed
      
    - name: Display NVIDIA driver and CUDA information
      debug:
        msg: "{{ nvidia_smi_output.stdout_lines | default(['NVIDIA information not available']) }}"
      when: driver_installed and nvidia_smi_output.stdout is defined
      
    # Configure for compute optimization with display
    - name: Create X11 configuration directory
      file:
        path: /etc/X11/xorg.conf.d
        state: directory
        mode: '0755'
      when: 
        - driver_install.changed 
        - var_environment == "production"
      register: x11_config_dir
      
    - name: Explain X11 configuration skip reason
      debug:
        msg: "Skipping X11 configuration directory creation: {% if not driver_install.changed %}Driver not being installed or updated{% elif var_environment != 'production' %}Running in TEST mode{% else %}Unknown reason{% endif %}"
      when: 
        - driver_install is defined
        - not (driver_install.changed and var_environment == "production")
        
    - name: Create GPU optimization configuration
      copy:
        content: |
          Section "Device"
              Identifier "NVIDIA"
              Driver "nvidia"
              Option "NoLogo" "true"
              # Not using UseDisplayDevice "None" since PiKVM is connected
              Option "RegistryDwords" "PerfLevelSrc=0x2222"
              Option "TripleBuffer" "True"
          EndSection
        dest: /etc/X11/xorg.conf.d/10-nvidia-compute.conf
        mode: '0644'
      when: 
        - driver_install.changed
        - var_environment == "production"
        
    - name: Explain GPU optimization configuration skip reason
      debug:
        msg: "Skipping GPU optimization configuration: {% if not driver_install.changed %}Driver not being installed or updated{% elif var_environment != 'production' %}Running in TEST mode{% else %}Unknown reason{% endif %}"
      when: 
        - driver_install is defined
        - not (driver_install.changed and var_environment == "production")
      
    # NVENC configuration for transcoding
    - name: Ensure NVENC is enabled for transcoding
      lineinfile:
        path: /etc/modprobe.d/nvidia.conf
        line: "options nvidia NVreg_RestrictProfilingToAdminUsers=0"
        create: yes
        mode: '0644'
      when: 
        - driver_install.changed
        - var_environment == "production"
        
    - name: Explain NVENC configuration skip reason
      debug:
        msg: "Skipping NVENC configuration: {% if not driver_install.changed %}Driver not being installed or updated{% elif var_environment != 'production' %}Running in TEST mode{% else %}Unknown reason{% endif %}"
      when: 
        - driver_install is defined
        - not (driver_install.changed and var_environment == "production")
      
    # Docker GPU passthrough setup - Updated section
    - name: Install NVIDIA Container Toolkit
      block:
        - name: Add NVIDIA Container Toolkit repository key
          apt_key:
            url: https://nvidia.github.io/nvidia-container-runtime/gpgkey
            state: present
          failed_when: false

        - name: Add NVIDIA Container Toolkit repository
          apt_repository:
            repo: "deb https://nvidia.github.io/libnvidia-container/stable/ubuntu/{{ ansible_distribution_version }}/amd64 /"
            state: present
            filename: nvidia-container-toolkit
            
        - name: Install NVIDIA Container Toolkit packages
          apt:
            name:
              - nvidia-container-toolkit
              - nvidia-container-runtime
            state: present
            update_cache: yes
            
        # New step: Configure Docker to use NVIDIA runtime
        - name: Configure NVIDIA Container Toolkit for Docker
          shell: nvidia-ctk runtime configure --runtime=docker
          register: nvidia_ctk_config
          changed_when: nvidia_ctk_config.rc == 0
            
        - name: Configure Docker for NVIDIA GPU (if Docker exists)
          copy:
            content: |
              {
                "runtimes": {
                  "nvidia": {
                    "path": "/usr/bin/nvidia-container-runtime",
                    "runtimeArgs": []
                  }
                }
              }
            dest: /etc/docker/daemon.json
            mode: '0644'
          register: docker_config
          failed_when: false
            
        - name: Restart Docker service if it exists
          systemd:
            name: docker
            state: restarted
          failed_when: false
          when: docker_config.changed or nvidia_ctk_config.changed
          
        # Verify Docker NVIDIA runtime is working
        - name: Test NVIDIA runtime with Docker
          shell: docker run --rm --gpus all ubuntu nvidia-smi
          register: docker_nvidia_test
          changed_when: false
          failed_when: false
          
        - name: Display NVIDIA Docker test results
          debug:
            msg: "{{ docker_nvidia_test.stdout_lines | default(['NVIDIA Docker test failed']) }}"
          when: docker_nvidia_test.rc == 0
          
        - name: Display NVIDIA Docker test error
          debug:
            msg: "NVIDIA Docker test failed with error: {{ docker_nvidia_test.stderr | default('Unknown error') }}"
          when: docker_nvidia_test.rc != 0
      when: 
        - driver_install.changed or not driver_installed
        - var_environment == "production"
        
    - name: Explain NVIDIA Container Toolkit skip reason
      debug:
        msg: "Skipping NVIDIA Container Toolkit installation: {% if not driver_install.changed %}Driver not being installed or updated{% elif var_environment != 'production' %}Running in TEST mode{% else %}Unknown reason{% endif %}"
      when: 
        - driver_install is defined
        - not (driver_install.changed and var_environment == "production")
            
    # Persistence mode for faster GPU response
    - name: Create nvidia-persistenced configuration directory
      file:
        path: /etc/nvidia-persistenced
        state: directory
        mode: '0755'
      when: 
        - driver_install.changed
        - var_environment == "production"
        
    - name: Explain persistence directory skip reason
      debug:
        msg: "Skipping nvidia-persistenced directory creation: {% if not driver_install.changed %}Driver not being installed or updated{% elif var_environment != 'production' %}Running in TEST mode{% else %}Unknown reason{% endif %}"
      when: 
        - driver_install is defined
        - not (driver_install.changed and var_environment == "production")
        
    - name: Configure persistence mode settings
      copy:
        content: "persistence-mode=1"
        dest: /etc/nvidia-persistenced/configuration
        mode: '0644'
      when: 
        - driver_install.changed
        - var_environment == "production"
        
    - name: Explain persistence mode settings skip reason
      debug:
        msg: "Skipping persistence mode configuration: {% if not driver_install.changed %}Driver not being installed or updated{% elif var_environment != 'production' %}Running in TEST mode{% else %}Unknown reason{% endif %}"
      when: 
        - driver_install is defined
        - not (driver_install.changed and var_environment == "production")
        
    - name: Enable Nvidia Persistence Daemon
      systemd:
        name: nvidia-persistenced
        enabled: yes
        state: started
      failed_when: false
      when: 
        - driver_install.changed
        - var_environment == "production"
        
    - name: Explain persistence daemon enabling skip reason
      debug:
        msg: "Skipping nvidia-persistenced daemon activation: {% if not driver_install.changed %}Driver not being installed or updated{% elif var_environment != 'production' %}Running in TEST mode{% else %}Unknown reason{% endif %}"
      when: 
        - driver_install is defined
        - not (driver_install.changed and var_environment == "production")
      
    # Final restart if needed
    - name: Restart system if required
      reboot:
        reboot_timeout: 600
      when: 
        - restart_after_install == "true"
        - driver_install.changed
        - var_environment == "production"
        
    - name: Explain system restart skip reason
      debug:
        msg: "Skipping system restart: {% if restart_after_install != 'true' %}Restart not enabled in configuration{% elif not driver_install.changed %}Driver not being installed or updated{% elif var_environment != 'production' %}Running in TEST mode{% else %}Unknown reason{% endif %}"
      when: 
        - driver_install is defined
        - not (restart_after_install == "true" and driver_install.changed and var_environment == "production")